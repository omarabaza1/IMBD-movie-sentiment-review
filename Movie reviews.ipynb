{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34629c6c-2b05-4043-9cf4-f56ac0133813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\omara\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\omara\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omara\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omara\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\omara\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omara\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9b3059-3e73-4594-b1eb-fd1b9df8a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D , Dense, TextVectorization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649aced2-7c9e-4d99-afc1-d0ced9abefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "SEQUENCE_LENGTH = 256\n",
    "EMBEDDING_DIM = 32  \n",
    "BATCH_SIZE = 32\n",
    "VOCAB_SIZE = MAX_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23e1d06-441e-40a8-9420-aa09b629a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset (Top 10000 words)...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading IMDB dataset (Top {MAX_FEATURES} words)...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64e6cba-6aa2-4a06-bd69-fdde34fbca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw , y_train), (X_test_raw, y_test) = tf.keras.datasets.imdb.load_data(num_words = MAX_FEATURES ,oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14cf605-0665-4e92-b751-624b6f96205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding sequences to fixed length of 256...\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPadding sequences to fixed length of {SEQUENCE_LENGTH}...\")\n",
    "\n",
    "X_train = pad_sequences(\n",
    "    X_train_raw , \n",
    "    maxlen=SEQUENCE_LENGTH,\n",
    "    padding = 'post',\n",
    "    truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285d58ac-79f0-49c3-b907-08e8d9304369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(\n",
    "    X_test_raw,\n",
    "    maxlen=SEQUENCE_LENGTH,\n",
    "    padding='post',\n",
    "    truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d378f46-1b7d-4158-8c44-d31f6ef25a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Samples Shape: (25000, 256)\n",
      "Final Testing Samples Shape: (25000, 256)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)\n",
    "print(f\"Final Training Samples Shape: {X_train.shape}\")\n",
    "print(f\"Final Testing Samples Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538e24d1-ae30-4931-8777-7d110e8414a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\n",
      "--- Model Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,545</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,545\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,545</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,545\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Embedding(VOCAB_SIZE,EMBEDDING_DIM,name=\"embedding_layer\",mask_zero=True),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1,activation='sigmoid'),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "try:\n",
    "    _ = model.predict(X_test[:1])\n",
    "except Exception as e:\n",
    "    # We ignore the prediction result, we only care that the model ran once.\n",
    "    pass\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Display the model architecture (Now the summary will show parameter counts!)\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cd3a8c-01ea-48a7-9780-4b1debade240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Model Trainig(running for 5 epochs)---\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "print(f\"\\n---Model Trainig(running for {EPOCHS} epochs)---\")\n",
    "start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6cb85a-ced4-4b25-b89e-7b2bf1090f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5607 - val_accuracy: 0.8667 - val_loss: 0.3167\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.2625 - val_accuracy: 0.8718 - val_loss: 0.3038\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2058 - val_accuracy: 0.8655 - val_loss: 0.3230\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1718 - val_accuracy: 0.8577 - val_loss: 0.3551\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1469 - val_accuracy: 0.8508 - val_loss: 0.3972\n",
      "\n",
      "Trainng completed in 11.25seconds.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)\n",
    "end_time = time.time()\n",
    "print(f\"\\nTrainng completed in {end_time - start_time:.2f}seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc703218-839c-4d01-b18b-12af99fa999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Test Loss: 0.3972\n",
      "Test Accuracy: 0.8508\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     12500\n",
      "           1       0.88      0.81      0.84     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f75c126c-bf47-4f78-9152-f15d625c4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text_sequence, index_mapping):\n",
    "    \"\"\"Converts an integer sequence back to human-readable text.\"\"\"\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in index_mapping.items()])\n",
    "    # Indices are offset by 3 for: <pad>, <start>, <unknown>\n",
    "    decoded_words = [reverse_word_index.get(i - 3, '?') for i in text_sequence if i > 0]\n",
    "    return ' '.join(decoded_words)\n",
    "\n",
    "# Load the word index dictionary\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# Example Test Case 1: Positive Review\n",
    "new_review_text_1 = \"This movie is truly one of the greatest cinematic achievements of the decade.\"\n",
    "new_review_sequence_1 = [word_index.get(word, 2) + 3 for word in new_review_text_1.lower().split()]\n",
    "\n",
    "# Example Test Case 2: Negative Review\n",
    "new_review_text_2 = \"What a dull and pointless film. The plot was thin and the characters were unconvincing.\"\n",
    "new_review_sequence_2 = [word_index.get(word, 2) + 3 for word in new_review_text_2.lower().split()]\n",
    "\n",
    "# Pad the new sequences\n",
    "new_sequences = pad_sequences(\n",
    "    [new_review_sequence_1, new_review_sequence_2], \n",
    "    maxlen=SEQUENCE_LENGTH, \n",
    "    padding='post', \n",
    "    truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11801100-e845-4634-b4e7-b9e216bd7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- Prediction on New Reviews ---\n",
      "Review 1: 'This movie is truly one of the greatest cinematic achievements of the decade.'\n",
      "Prediction: Positive (Confidence: 0.9657)\n",
      "\n",
      "Review 2: 'What a dull and pointless film. The plot was thin and the characters were unconvincing.'\n",
      "Prediction: Negative (Confidence: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(new_sequences)\n",
    "\n",
    "print(\"\\n--- Prediction on New Reviews ---\")\n",
    "print(f\"Review 1: '{new_review_text_1}'\")\n",
    "print(f\"Prediction: {'Positive' if predictions[0][0] > 0.5 else 'Negative'} (Confidence: {predictions[0][0]:.4f})\")\n",
    "\n",
    "print(f\"\\nReview 2: '{new_review_text_2}'\")\n",
    "print(f\"Prediction: {'Positive' if predictions[1][0] > 0.5 else 'Negative'} (Confidence: {predictions[1][0]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18b402-d5a7-4ee0-adb4-64377f2bfc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
